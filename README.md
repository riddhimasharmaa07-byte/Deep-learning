# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XXp1pq9aBKzYwrHSdMsGzSQbQaYA1R2A
"""

#How to import dataset using python?

import pandas as pd









df=pd.read_csv('/content/Final.csv',encoding='latin1')

print(df.head(20))

df.shape

df.describe()

df=pd.read_csv('/content/iris.csv',encoding='latin1')

print(df.head(20))

df.shape

df.describe()

import pandas as pd
import numpy as np

from sklearn.linear_model import LinearRegression

#example dataset (for nations and it's count of people)
nation= np.array(['india','china','japan','pakistan']).reshape(-1,1)
people=np.array([170,168,59,70])

model = LinearRegression()

# Create a mapping from nation names to numerical values for the example data
nation_mapping = {
    'india': 0,
    'china': 1,
    'japan': 2,
    'pakistan': 3
}

# Convert the nation names to their numerical representations
nation_numeric = np.array([nation_mapping[n[0]] for n in nation]).reshape(-1, 1)

model.fit(nation_numeric, people)

user_nation_name = input("Enter the nation (india, china, japan, or pakistan): ").lower()

# Convert the input nation name to its numerical representation
if user_nation_name in nation_mapping:
    user_nation_numeric = nation_mapping[user_nation_name]
    predicted_people = model.predict([[user_nation_numeric]])
    print(f"Predicted people for {user_nation_name.capitalize()}: {predicted_people[0]:.2f} crores")
else:
    print("Invalid nation entered. Please enter one of the example nations.")

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

x=load_iris().data
y=load_iris().target

load_iris().target

x_train, x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)
model = LogisticRegression()
model.fit(x_train,y_train)
predictions = model.predict(x_test)
print("Accuracy:", accuracy_score(y_test, predictions))
print("Classification Report:\n", classification_report(y_test, predictions))
print("Confusion Matrix:\n", confusion_matrix(y_test, predictions))

import pandas as pd

df=pd.read_csv('/content/Iris.csv',encoding='latin1')

df.drop("Species", axis=1, inplace=True)

x=load_iris().data
y=load_iris().target

print(sns.get_dataset_names())

df1=sns.load_dataset('planets')

df1

import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Load the iris dataset
df = sns.load_dataset('iris')

# Features (X) and target (y)
X = df.drop('species', axis=1)
y = df['species']

# Train-test split (stratify keeps class balance)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Logistic Regression (multi-class)
model = LogisticRegression(max_iter=200, multi_class='multinomial')
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression (Iris)")
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import
from sklearn.metrics import r2_score,mean_squared_error

# sample dataset (height, weight --> bmi)
data = {
    "height":[1,2,3,4,5,6,7,8,9,10],
    "weight": [90, 60 , 100, 70 , 85 , 89 , 87 , 34 ,8 , 100],
    "bmi": [850000 , 50000 , 92000 , 650000 , 800000 , 90000, 95000, 80000, 98000 , 88000]
}

# convert to dataframe
df = pd.DataFrame(data)

# features (x) and target (y)
x = df[['height', 'weight']]
y = df['bmi']

# Train-Test split (80% train, 20% test)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Build model
model = LinearRegression()
model.fit(x_train, y_train)

# coefficients and intercept
print("coefficients: ", model.coef_)
print("intercept: ", model.intercept_)

# Make predictions
y_pred = model.predict(x_test)

# evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse)
print("R-squared: ", r2)

# compare actual vs predicted
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(comparison)

# sample dataset (height, weight --> bmi)
data = {
    "height":[1,2,3,4,5,6,7,8,9,10],
    "weight": [90, 60 , 100, 70 , 85 , 89 , 87 , 34 ,8 , 100],
    "bmi": [850000 , 50000 , 92000 , 650000 , 800000 , 90000, 95000, 80000, 98000 , 88000]
}

# convert to dataframe
df = pd.DataFrame(data)

# features (x) and target (y)
x = df[['height', 'weight']]
y = df['bmi']

# Train-Test split (80% train, 20% test)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Build model
model = LinearRegression()
model.fit(x_train, y_train)

# coefficients and intercept
print("coefficients: ", model.coef_)
print("intercept: ", model.intercept_)

# Make predictions
y_pred = model.predict(x_test)

# evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse)
print("R-squared: ", r2)

# compare actual vs predicted
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(comparison)

# sample dataset (height, weight --> bmi)
data = {
    "height":[1,2,3,4,5,6,7,8,9,10],
    "weight": [90, 60 , 100, 70 , 85 , 89 , 87 , 34 ,8 , 100],
    "bmi": [850000 , 50000 , 92000 , 650000 , 800000 , 90000, 95000, 80000, 98000 , 88000]
}

# convert to dataframe
df = pd.DataFrame(data)

# features (x) and target (y)
x = df[['height', 'weight']]
y = df['bmi']

# Train-Test split (80% train, 20% test)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Build model
model = LinearRegression()
model.fit(x_train, y_train)

# coefficients and intercept
print("coefficients: ", model.coef_)
print("intercept: ", model.intercept_)

# Make predictions
y_pred = model.predict(x_test)

# evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse)
print("R-squared: ", r2)

# compare actual vs predicted
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(comparison)

#sample dataset(study housed,attas)
data = {'fly_hours': [10, 20, 30, 40, 50],
        'distance': [100, 200, 300, 400, 500],
        'payment': [150, 250, 350, 450, 550]}

df = pd.DataFrame(data)

from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

digits=datasets.load_digits()
X = digits.data
Y = digits.target

print("Dataset Shape:", X.shape)
print("Target Shape:", y.shape)

#show first sample image
plt.gray()
plt.matshow(digits.images[0])
plt.show()

X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

k=5
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X_train, y_train)

y_pred=knn.predict(X_test)
print("\nAccuracy:",accuracy_score(y_test,y_pred))
print("\nClassification Report:\n",classification_report(y_test,y_pred))
print("\nConfusion Matrix:\n",confusion_matrix(y_test,y_pred))



import pandas as pd
import numpy as np

# Load the pokemon dataset
try:
    df = pd.read_csv('/content/pokemon.csv')
    print("Available columns:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'pokemon.csv' not found. Please make sure the file is uploaded to '/content/'.")
    df = None

print(df.columns)

# Split the dataset into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a KNN classifier
from sklearn.neighbors import KNeighborsClassifier
k = 5 # You can choose a different value for k
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X_train, y_train)

# Step 1: Upload the file
from google.colab import files
uploaded = files.upload()

# Step 2: Extract the zip file
import zipfile
import os

zip_path = "archive.zip"  # Change if filename differs
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("dataset")

# Check extracted files
os.listdir("dataset")

# Step 3: Load the dataset
import pandas as pd

# Replace with actual filename after extraction
df = pd.read_csv("dataset/archive.csv")
print(df.head())
print(df.info())

# Step 4: Preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Example: Assume last column is target
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# Encode target if categorical
if y.dtype == "object":
    le = LabelEncoder()
    y = le.fit_transform(y)

# Scale features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Apply KNN
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Step 6: Evaluate
y_pred = knn.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))



from google.colab import drive
drive.mount('/content/drive')
